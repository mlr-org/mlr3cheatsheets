\documentclass{beamer}

\usepackage[orientation=landscape,size=a0,scale=1.4,debug]{beamerposter}
\mode<presentation>{\usetheme{mlr}}

\usepackage[sfdefault]{roboto}
\usepackage{roboto-mono}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc} % UTF-8
\usepackage[english]{babel} % Language
\usepackage{hyperref} % Hyperlinks
\usepackage{ragged2e} % Text position
\usepackage[export]{adjustbox} % Image position
\usepackage[most]{tcolorbox} % Code boxes
\usepackage{multido}

\hypersetup{
	hyperfootnotes=false,
	colorlinks=true,
	linktocpage=true,
	pdfauthor={mlr-org team},
	%linkcolor=[RGB]{3,99,142}, % mlr blue
	urlcolor=[RGB]{231,138,69}
}

\title{Hyperparameter Tuning with mlr3tuning :\,: CHEAT SHEET} % Package title in header, \, adds thin space between ::

\newlength{\columnheight} % Adjust depending on header height
\setlength{\columnheight}{84cm} 

\newtcolorbox{codebox}{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	fontupper=\robotomono\small,
	hbox}

\newtcolorbox{codeboxmultiline}[1][]{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	fontupper=\robotomono\small,
	#1}

\newtcolorbox{codeboxexample}{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	fontupper=\robotomono\small,
	width=27cm,
	adjusted title=Example,
	fonttitle = \bfseries\Large,
	top = 0.5em}

\newtcolorbox{codeboxinline}{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	hbox,
	nobeforeafter,
	fontupper=\robotomono\small,
	tcbox raise base}

\newcommand{\codeinline}[1]{\begin{codeboxinline}#1\end{codeboxinline}}
\newcommand{\sectionheading}[1]{{\color{mlrblue}\large\raggedright\textbf{#1}}\vspace{1em}}
\newcommand{\monospace}[1]{\multido{}{#1}{\space}}

\begin{document}
\begin{frame}[fragile]{}
	\begin{columns}
		\begin{column}{.245\textwidth}
			\begin{beamercolorbox}[center]{postercolumn}
				\begin{minipage}{.98\textwidth}
					\parbox[t][\columnheight]{\textwidth}{
						\begin{myblock}{Overview of Classes}
                            The package provides a set of classes which allow to (a) define general 
                            hyperparameter (HP) tuning problems and (b) search algorithms which act on these. (a) is called a TuningInstance, which defines a blackbox optimization function that maps HP candidate configurations to resampled performance values for arbitrary performance measures.\\
                            \\
                            \vspace{1em}
                            \includegraphics[width=\textwidth]{img/class_diagram.pdf}
						\end{myblock}
						\begin{myblock}{ParamSet - Params and Ranges}
					        % Hyperparameters and ranges for tuning (1). 
					        Scalar doubles, ints, factors, logicals are combined 
					        in set to define multivariate tuning space.
							\\
							\begin{codeboxmultiline}[width=20.75cm]
								tune\_ps = \textbf{ParamSet}\$new(list(\\
								\hspace*{1ex}\textbf{ParamInt}\$new(id, lower, upper),\\
								\hspace*{1ex}\textbf{ParamDbl}\$new(id, lower, upper),\\
								\hspace*{1ex}\textbf{ParamFct}\$new(id, levels),\\
								\hspace*{1ex}\textbf{ParamLgl}\$new(id)))
							\end{codeboxmultiline}
                            \codeinline{id} is param name in learner. 
                            \codeinline{lower}/\codeinline{upper} define 
                            numerical range, \codeinline{levels} for categories.
                            \vspace{1em}
                            \\ 
                            \sectionheading{Transformations for Rescaling}
							\begin{codeboxmultiline}[width=25.5cm]
								tune\_ps\$\textbf{trafo} = function(x, param\_set) \{\\
								\hspace*{1ex}x\$id = -log(x\$id); return(x)\}      
							\end{codeboxmultiline}
							Set a transformation for param \codeinline{id} which  
                            allows the rescaling of (parts of) the configuration 
							before passing it to the \codeinline{Learner}.
                            \vspace{1em}
							\\
                            \sectionheading{Dependencies}
                            \\
                            Dependencies prevent HP configurations that are not usable by the learner.
                            \\
							\begin{codebox}
								tune\_ps\$\textbf{add\_dep}(id, on, cond)
							\end{codebox}
							Adds dependency to the \codeinline{ParamSet}, 
							so that \codeinline{id} depends on parameter \codeinline{on}.
							\codeinline{cond} is \codeinline{CondEqual\$new(rhs)} or \codeinline{CondAnyOf\$new(rhs)}.
						\end{myblock}
						\vfill}
				\end{minipage}
			\end{beamercolorbox}
		\end{column}
		\begin{column}{.245\textwidth}
			\begin{beamercolorbox}[center]{postercolumn}
				\begin{minipage}{.98\textwidth}
					\parbox[t][\columnheight]{\textwidth}{
                        \begin{myblock}{Terminators - When to stop}
							Create with \codeinline{\textbf{term}(.key, ...)}
							\\
							\begin{itemize}
                                \item \codeinline{evals}
                                (\codeinline{n\_evals})\\
                                After a given amount of iterations.
								\item \codeinline{clock\_time} 
								(\codeinline{secs}, \codeinline{stop\_time})\\
								After a given absolute time.
								\item \codeinline{model\_time}
								(\codeinline{secs })\\
								After a given model time.
								\item \codeinline{perf\_reached}
								(\codeinline{level})\\
								After a specific numerical performance was reached.
								\item \codeinline{stagnation}
								(\codeinline{iters}, \codeinline{threshold})\\
								After the performance stagnates.
							\end{itemize}
							\vspace{1em}
							\begin{codebox}
								as.data.table(\textbf{mlr\_terminators})
							\end{codebox}
							Lists terminator dictionary.
							\\
							\begin{codebox}
								terminator = term("\textbf{combo}", terminators, any)
							\end{codebox}
							List of \codeinline{terminators} that terminate 
							if any (\codeinline{any = TRUE}) 
							or all (\codeinline{any = FALSE}) terminators are positive.
						\end{myblock}
                        \begin{myblock}{TuningInstance - Search Scenario}
							Evaluator 
							and container for resampled performances 
							of HP configurations duing tuning. 
							\\
							\begin{codeboxmultiline}[width=23.7cm]
								instance = \textbf{TuningInstance}\$new(\\
								\hspace*{1ex}task, learner, resampling, measures,\\
								\hspace*{1ex}tune\_ps, terminator, bm\_args)
							\end{codeboxmultiline}
							\vspace{1em}
							\begin{codeboxexample}
								{\tiny
                                    \# optimize hyperpar of RBF SVM on logscale\\
									learner = lrn("classif.svm", kernel = "radial")\\
									tune\_ps = ParamSet\$new(list(\\
									\hspace*{1ex} ParamDbl\$new("cost", lower = -8, upper = 8),\\
									\hspace*{1ex} ParamDbl\$new("gamma", lower = -8, upper = 8)))\\
									tune\_ps\$trafo = function(x, param\_set) \{\\
									\hspace*{1ex} x\$cost = 2\textasciicircum x\$cost; x\$gamma = 2\textasciicircum x\$gamma; x\}\\
									evals20 = term("evals", n\_evals = 20)\\
									instance = TuningInstance\$new(\\
									\hspace*{1ex} task, learner, resampling, measures, tune\_ps, evals20)\\
									tuner = tnr("random\_search")\\
									tuner\$tune(instance)\\
									instance\$result}
							\end{codeboxexample}
						\end{myblock}
						\vfill}
				\end{minipage}
			\end{beamercolorbox}
		\end{column}
		\begin{column}{.245\textwidth}
			\begin{beamercolorbox}[center]{postercolumn}
				\begin{minipage}{.98\textwidth}
					\parbox[t][\columnheight]{\textwidth}{
						\begin{myblock}{Tuner - Search Strategy}
                            Tuning strategy. Generates candidate configurations 
                            and passes them to \codeinline{TuningInstance} for evaluation until termination. 
                            Create witth \codeinline{\textbf{tnr}(.key, ...)}
							\\
							\begin{itemize}
								\item \codeinline{grid\_search}
								(\codeinline{resolution}, \codeinline{batch\_size})\\
								Grid search.
								\item \codeinline{random\_search}
								(\codeinline{batch\_size})\\
								Random search.
								\item \codeinline{gensa}
								(\codeinline{smooth}, \codeinline{temperature})\\
								Generalized simulated annealing.
								\item \codeinline{design\_points}
								(\codeinline{batch\_size }, \codeinline{design})\\
								All points user-specified.
							\end{itemize}
							\vspace{1em}
							\begin{codebox}
								as.data.table(\textbf{mlr\_tuners})
							\end{codebox}
							Lists tuner dictionary.
						\end{myblock}
						\begin{myblock}{Running the Tuning}
							\begin{codebox}
								tuner\$\textbf{tune}(instance)
							\end{codebox}
							Starts the tuning. \codeinline{Tuner} generates candidate configurations
							and passes them to the \codeinline{\$eval()} method of \codeinline{TuningInstance}
							until the budget of \codeinline{Terminator} is exhausted.
							\\
							\begin{codebox}
								instance\$\textbf{archive}(unnest = TRUE)
							\end{codebox}
							Returns all tried configurations and their resampling results. 
							Use \codeinline{unnest} to display HP without
							(\codeinline{tune\_x}) or with (\codeinline{params}) trafo applied.
							\\
							\begin{codeboxmultiline}[width=24.75cm]
								{\tiny
									instance\$archive()\\
									\#\# nr batch\_nr ... resample\_result\monospace{2}iters params tune\_x classif.ce\\
									\#\#\monospace{2}1\monospace{8}1 ...\monospace{1}<ResampleResult> 
									\monospace{4}5 <list> <list>\monospace{2}0.2825482\\
									\#\#\monospace{2}2\monospace{8}1 ...\monospace{1}<ResampleResult>
									\monospace{4}5 <list> <list>\monospace{2}0.2825482\\
									\#\#\monospace{2}3\monospace{8}2 ...\monospace{1}<ResampleResult>
									\monospace{4}5 <list> <list>\monospace{2}0.2696206\\
									\#\#\monospace{2}4\monospace{8}2 ...\monospace{1}<ResampleResult>
									\monospace{4}5 <list> <list>\monospace{2}0.2721586}
							\end{codeboxmultiline}
							\vspace{1em}
							\begin{codebox}
								instance\$\textbf{result}
							\end{codebox}
							Returns list with optimal configuration and estimated performance.
							\\
							\begin{codebox}
								{\footnotesize learner\$param\_set\$\textbf{values} = instance\$result\$\textbf{params}}
							\end{codebox}
							Set optimized HP in \codeinline{Learner}.
						\end{myblock}
						\vfill}
				\end{minipage}
			\end{beamercolorbox}
		\end{column}
		\begin{column}{.245\textwidth}
			\begin{beamercolorbox}[center]{postercolumn}
				\begin{minipage}{.98\textwidth}
					\parbox[t][\columnheight]{\textwidth}{
						\begin{myblock}{AutoTuner - Tune before Train}
							Wraps learner and adds automatic tuning. 
							\\
							\begin{codeboxmultiline}[width=23.75cm]
								at = \textbf{AutoTuner}\$new(\\
								\hspace*{1ex}learner, resampling, measures, \\
								\hspace*{1ex}tune\_ps, terminator, tuner, bm\_args)
							\end{codeboxmultiline}
							\vspace{0.5em}
                            Inherits from \codeinline{Learner} class; can be used like it. 
                            Training starts tuning on the training set,
                            and after completion trains the learner finally with 
                            this the optimal configuration on the full training set.
							\begin{codeboxmultiline}[width=16.5cm]
								at\$\textbf{train}(task)\\
								at\$\textbf{predict}(task, row\_ids)
							\end{codeboxmultiline}
						\end{myblock}
						\begin{myblock}{Nested Resampling}
							Resampling the \codeinline{AutoTuner} achieves nested resampling 
							with an inner and outer loop. 
							\\
							\begin{codeboxexample}
								{\scriptsize
									resampling\_inner = rsmp("holdout")
									\vspace{1em}
									\\
									at = AutoTuner\$new(learner, resampling\_inner, \\
									\hspace*{1ex}measures, tune\_ps, evals20, tuner) \\
									at\$store\_tuning\_instance = TRUE
									\vspace{1em}
									\\
									resampling\_outer = rsmp("cv", folds = 2)\\
									rr = resample(task, at, resampling\_outer, \\
									\hspace*{1ex}store\_models = TRUE)
									\vspace{1em}
									\\
									rr\$data\\
									\#\# ...\monospace{3}learner\monospace{5}resampling iteration
									prediction\\
									\#\# ... <AutoTuner> <ResamplingCV>\monospace{9}1\monospace{5}<list>\\
									\#\# ... <AutoTuner> <ResamplingCV>\monospace{9}2\monospace{5}<list>}
							\end{codeboxexample}
							\vspace{1em}
							\begin{codebox}
								rr\$\textbf{aggregate()}
							\end{codebox}
							Aggregates performance of outer results.
							\\
							\begin{codebox}
								rr\$data\$learner[[1]]\$\textbf{tuning\_result}
							\end{codebox}
							Retrieve inner tuning results.
						\end{myblock}
						\begin{myblock}{Logging and Parallelization}
							\begin{codebox}
								{\scriptsize
									lgr::get\_logger("\textbf{mlr3/mlr3tuning}")\$set\_threshold("<level>")}
							\end{codebox}
							Change log-level only for mlr3tuning.\\
							\begin{codebox}
								future::\textbf{plan}(strategy)
							\end{codebox}
							Selects the parallelization strategy.
							Speeds up the tuning by running resample iterations in parallel.
						\end{myblock}
						\vfill}
				\end{minipage}
			\end{beamercolorbox}
		\end{column}
	\end{columns}
\end{frame}
\end{document}
